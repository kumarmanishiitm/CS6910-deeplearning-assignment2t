# -*- coding: utf-8 -*-
"""cmdpartB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JzCkiUXt_Ngak4RZ1vxcM_hsqghVztnT
"""

# Commented out IPython magic to ensure Python compatibility.
#Import and install required libraries
import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Flatten, Conv2D,Dense,MaxPooling2D,Dropout,BatchNormalization,Activation 
from PIL import Image
# %matplotlib inline
# %config InlineBackend.figure_format = 'svg'
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
## Prepare the dataset for training
def dataset_Training(Dataset_loc="inaturalist_12K", augment_data=False,ts=(299,299)):
    Directory_train= os.path.join(Dataset_loc, "train")
    Directory_test= os.path.join(Dataset_loc, "val")

    if augment_data:
        generator_train=ImageDataGenerator(rescale=1./255,rotation_range=90,zoom_range=0.2,shear_range=0.2,horizontal_flip=True)
    else:
        generator_train=ImageDataGenerator(rescale=1./255)
       
    generator_test = ImageDataGenerator(rescale=1./255)
    train_generate = generator_train.flow_from_directory(Directory_train, target_size=ts, batch_size=128, subset="training",shuffle=True,seed=8700)
    #val_generate = generator_train.flow_from_directory(Directory_train, target_size=ts, batch_size=128, subset="validation",shuffle=True,seed=8700)
    test_generate = generator_test.flow_from_directory(Directory_test, target_size=ts, batch_size=128)
    
    return train_generate, test_generate
train_ds, val_ds = dataset_Training()
def our_Model(name):
  if name=="InceptionV3":
    w,ht=299,299
    return tf.keras.applications.InceptionV3(include_top=False, input_shape=(w,ht,3), weights='imagenet')
  elif name=="InceptionResNetV2":
    w,ht=299,299
    return tf.keras.applications.InceptionResNetV2(include_top=False, input_shape=(w,ht,3), weights='imagenet')
  elif name=="ResNet50":
    w,ht=224,224
    return tf.keras.applications.ResNet50(include_top=False, input_shape=(w,ht,3), weights='imagenet')
  elif name=="Xception":
    w,ht=299,299
    return tf.keras.applications.Xception(include_top=False, input_shape=(w,ht,3), weights='imagenet')


def train_model(base_model,dense_Size,batch_normalisation,epochs,augment_data,dropout,lr):
  ## 1. Data loading
  img_height,img_width=(299,299)
  print("1. Loading the dataset ...\n")
  if base_model=="ResNet50":
    img_height,img_width=224,224
    train_ds, val_ds=dataset_Training(augment_data=augment_data,ts=(img_height,img_width))
  else:
     train_ds, val_ds=dataset_Training(augment_data=augment_data,ts=(img_height,img_width))
  O_model=our_Model(base_model)

  for layers in O_model.layers:
    layers.trainable = False

  model = keras.Sequential([
    tf.keras.Input(shape=(img_height, img_width,3,)),
    O_model,
    Flatten(),
    Dense(dense_Size,activation='relu'),
      
  ])
  if batch_normalisation == True:
    model.add(BatchNormalization())
  model.add(Dropout(dropout))
  model.add(Dense(dense_Size,activation='relu'))
  model.add(Dropout(dropout))
  model.add(Dense(10 ,activation='softmax'))
  
  to_tune_defaults = {
        "InceptionV3": 55,
        "InceptionResNetV2": 55,
        "ResNet50": 50,
        "Xception": 50
  } 
  #train_ds, val_ds,y = load_data(cofig.augment_data)
  model.trainable =True
  print(f"Total layers in base model is {len(model.layers)}\n")

  fine_tune_at = len(model.layers) - int(.01*len(model.layers)*to_tune_defaults[base_model])
  for layer in model.layers[:fine_tune_at]:
      layer.trainable =False

  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
                  loss=tf.keras.losses.CategoricalCrossentropy(),
                  metrics=['accuracy'])
    
  print("Fine tuning the model ...\n")
  model.fit(train_ds, 
              validation_data=val_ds,
              epochs=epochs)
  print("Model tuned successfully!!\n")

from sys import argv
if __name__ == "__main__":

    if(len(argv) !=8):
        print("Invalid num of parameters passed ")
        exit()
    base_model=argv[1]
    dense_Size=int(argv[2])
    
    if argv[3] == "True":
      batch_normalisation = True
    else:
      batch_normalisation=False
    if argv[4]=="True":
      augment_data=True
    else:
      augment_data=False

    epochs = int(argv[5])
    dropout=float(argv[6])
    lr = float(argv[7])
    train_model(base_model,dense_Size,batch_normalisation,augment_data,epochs,dropout,lr)





